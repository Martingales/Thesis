%!TEX root = ../intro.tex
%******************************
%	 Bayesian approaches
%*****************************

\section{Bayesian approaches to model scRNAseq data}

In the last decade, an array of tools to process and analyse scRNA-Seq data has been developed. These methods include preliminary tools for data acquisition (e.g.~alignment, de-duplication, quantification), data filtering (e.g.~quality control, normalization, imputation), cell labelling (e.g.~clustering, classification, ordering) and gene-level analysis (e.g.~differential expression, detection of expression patterns) \citep{Zappia2018}. Extensive comparisons of these methods have been done in details depending on the type of analysis that need to be performed \citep{Saelens2018, Soneson2018}. At this point, I want to focus on Bayesian methods that were developed to estimate posterior distributions for model parameters to propagate uncertainty into downstream analysis. \\

\subsection{The basics of Bayesian inference}

The main difference between classical and Bayesian inference is the distributional assumption of the model parameters. While in classical inference, model parameters represent an fixed but unknown value, Bayesian approaches treat parameters as random variables to incorporate the uncertainty of parameter estimation \citep{Bernardo2003}. The aim of Bayesian inference is to find a \emph{posterior distribution} that captures the uncertainty of the model parameter $\omega$. Prior believes about the distribution of $\omega$ are summarized in form of a \emph{prior distribution} $\pi(\omega)$. Once the data $D$ is observed, the prior distribution $\pi^*(\omega|D)$  is updated to form the posterior distribution of the model parameter $\omega$. This is a simplified explanation of the Bayes Theorem \cite{Canton1763}:

\begin{equation} \label{eq0:Bayes_theorem}
\pi^*(\omega|D,\cdot)=\frac{L(D|\omega)\pi(\omega)}{L_\omega(D)}.
\end{equation}

Here, $L(D|\omega)$ is the likelihood of observing the data given the parameter $\omega$ and $L_\omega(D)$ is the marginal likelihood when integrating out the parameter $\omega$.\\

Bayes theorem in equation \ref{eq0:Bayes_theorem} can be simplified to:

\begin{equation}
\pi^*(\omega|D)=c(D)L(D|\omega)\pi(\omega)\propto{}L(D|\omega)\pi(\omega)
\end{equation} 

where $c(D)$ represents the proportionality constant $L_\omega(D)=\int_\omega{}L(D|\omega)\pi(\omega)d\omega$ and integrates to one when $\pi^*(\omega|D)$ is conjugate to the kernel function $L(D|\omega)\pi(\omega)$ \citep{Bernardo2003, Raiffa1961}. The definition of conjugate distributions is explained below.  

\subsection{Prior distributions}

The role of the prior distribution is to incorporate prior knowledge which is guides the data to form the posterior distribution. For this, a prior distribution needs to be chosen that adequately describes the experimenter's prior knowledge of the unknown parameters. For practical use, the prior distribution can be chosen to form a analytically tractable solution for the integration of $\int_\omega{}L(D|\omega)\pi(\omega)d\omega$. To find this distribution, the likelihood can be factorized into two terms: one that contains all constants independent of the model parameter $\omega$ and one factor that depends on the model parameter. A conjuage prior is of the same family of distributions as the factor depending on the model parameter. \citep{Fink1997}. Conjugate prior distributions are prior distributions of the same family as the posterior distribution. The choice of conjugate prior distributions also lead to a closed-form posterior distribution which facilitates posterior inference. A list of commonly used conjugate priors can be seen in Table \ref{tab0:priors}.

\begin{table}[hb	]
\centering
\caption{Conjugate prior distributions for common likelihood functions taken from \citep{Fink1997}}
\label{tab0:priors}
\begin{tabular}{l l l}
\toprule
\textbf{Discrete} & &\\
\midrule
\midrule
\textbf{Data generation process} & \textbf{Prior} & \textbf{Posterior} \\ 
\midrule 
Bernoulli & Beta & Beta \\
Poisson & Gamma  & Gamma \\
Negative Binomial & Beta & Beta \\
\midrule
\midrule
\textbf{Continous} & & \\
\midrule
\midrule
\textbf{Data generation process} & \textbf{Prior} & \textbf{Posterior} \\ 
\midrule
Uniform  & Pareto & Pareto \\ 
Normal (unknown mean) &  Normal  & Normal \\ 
Normal (unknown variance) &  Inverse Gamma  & Inverse Gamma \\ 
Gamma (unknown rate) &  Gamma  & Gamma \\ 
Exponential &  Gamma  & Gamma \\ 
\bottomrule
\end{tabular}
\end{table} 

When prior knowledge on the distribution of the model parameter is not available to select the prior distribution, non-informative or objective priors are used. The idea is that the "data should speak for itself" and therefore, these priors are chosen to have a minimal effect, relative to the data, on the posterior inference \citep{Bernardo2000}. The most commonly used non-informative prior is the Jeffreys prior \citep{Jeffreys1946} which is defined as the square root of the determinate of the Fisher information matrix. The use of non-informative priors can lead to improper posterior distributions. Furthermore, when $\int_\omega\pi(\omega)d\omega$ is infinite, the prior is called \emph{improper prior} and does not lead to a closed-form posterior distribution \citep{Bernardo2003}.

\subsection{Posterior inference}

Before the availability of computers, research centred around finding pairs of likelihood functions and prior distributions that produce well-defined and tractable solutions for posterior distributions (conjugate priors). More recently, the increase in computing power supported the development of numerical methods to approximate the integrals needed to form posterior distributions \citep{Fink1997}. Numerical approximations are needed when objective priors are used or for models with large complexity. When the model contains multiple parameters, it could be of interest to find univariate marginal posterior densities or multivariate joint marginal posterior densities of model parameters.\\

Multiple numerical approximation strategies have been described including: \emph{Laplace Approximation, Iterative Quadrature, Importance Sampling, Sampling-importance-resampling, Markov Chain Monte Carlo}. At this point, I like to focus on \emph{Markov Chain Monte Carlo (MCMC)} \citep{Metropolis1953, Hastings1970} as a sampling strategy to approximate posterior distributions.

\subsubsection{Markov Chain Monte Carlo}

The idea behind MCMC is to generate a sample of the posterior distribution $\pi^*(\omega|D)$ for $\omega\in\Omega$ when the distribution cannot be obtained directly. For this, a Markov chain with state space $\Omega$ is simulated over $n$ iterations whose equilibrium distribution is $\pi^*(\omega|D)$ \citep{Bernardo2000}. Extensive research lead to the development of algorithms that generate this equilibrium distribution \citep{Casella1992, Gelfand1990, Greyer1992, Besag1993, Gelman1992}.
The following two examples of MCMC are commonly used for a range of applications in Bayesian statistics \citep{Bernardo2000}.\\

\textbf{\textit{Gibbs sampling}}

We consider a complex model where $\bm{\theta}$ represents the vector of unknown parameters in Bayes theorem. The joint posterior $\pi^*(\bm{\theta}|D)=\pi^*(\theta_1,...,\theta_k|D)$ is not tractable and needs to be numerically approximated. To obtain posterior distributions for each model parameter $\theta_i$, one defines the \emph{full conditional} distribution:

\begin{equation}
\pi^*(\theta_i|D,\theta_j,j\neq{}i), \quad i=1,...,k
\end{equation}

This defines the density of the individual component $\theta_i$ given the data and specified values (current updates) of all other components $\theta_j$ \cite{Geman1984} and can easily be identified from the part of the posterior distribution depending on $\theta_i$ \citep{Bernardo2000}. In each iteration $t$ with $t=1,...,n$ every component $\theta_i,\,{}i=1,...,k$ is updated as followed:

\begin{align*}
\textnormal{draw} \quad  \theta_1^{(t+1}) \quad \textnormal{from} \quad & \pi^*(\theta|D, \theta_2^{(t)},...\theta_k^{(t)})\\
\textnormal{draw} \quad  \theta_2^{(t+1)} \quad \textnormal{from} \quad & \pi^*(\theta|D, \theta_1^{(t)},\theta_3^{(t)},...\theta_k^{(t)})\\
&.\\
&.\\
&.\\
\textnormal{draw} \quad  \theta_k^{(t+1)} \quad \textnormal{from}  \quad& \pi^*(\theta|D, \theta_1^{(t)},...\theta_{k-1}^{(t)})
\end{align*}

For $t\rightarrow{}\infty$ the joint distribution of $(\theta_1,...,\theta_k)$ converges against the posterior distribution of $\pi^*(\bm{\theta}|D)$ \citep{Roberts1994, Geman1984}. \\
The transitions probability density function is defined as:

\begin{equation}
p(\theta^t,\theta^{t+1})=\prod_{l=1}^k{}\pi(\theta_l^{t+1}|\theta_j^t,j>l,\theta_j^{t+1},j<l,D)
\end{equation}

The implementation of Gibbs sampling is straightforward when the full conditionals have a known form. For other distributions, stochastic simulation techniques can be used.\\

\textbf{\textit{Metropolis-Hastings}}

One of these techniques is the \emph{Metropolis-Hastings algorithm} \citep{Metropolis1953, hastings1970} which constructs a Markov chain $\theta_i^1,...,\theta_i^n$ with state space $\Theta$ as follows:\\
Let $q(\theta_i,\theta_i')$ be a transition probability density function given a current state $\theta_i^t=\theta_i$, then the vector $\theta_i'$ represents a proposed possible value for $\theta_i^{t+1}$ \citep{Bernardo2000}. Furthermore, with some probability $\alpha(\theta_i,\theta_i'|\theta_j,j\neq{}i)$ the proposed value $\theta_i'$ is accepted as $\theta_i^{t+1}=\theta_i'$ and otherwise rejected: $\theta_i^{t+1}=\theta_i^t$ \cite{Roberts1994, Hastings1970}. In practice, the update is found as follows:

\begin{enumerate}
\item Sample $\nu\sim\textnormal{Unif(0,1)}$ and a candidate $\theta_i'$ from $q(\theta_i,\theta_i')$.
\item Define

\begin{equation}
\alpha(\theta_i,\theta_i'|\theta_j,j\neq{}i)=\min\left\lbrace{}1,\frac{\pi^*(\theta_i'|D,\theta_j,j\neq{}i)q(\theta_i',\theta_i)}{\pi^*(\theta_i|D,\theta_j,j\neq{}i)q(\theta_i,\theta_i')}\right\rbrace
\end{equation}

\item If $\nu\leq{}\alpha(\theta_i,\theta_i'|\theta_j,j\neq{}i)$, return $\theta_i'$ otherwise return $\theta_i^t$
\end{enumerate}

For this algorithm, the transition probability density $q(\theta_i,\theta_i')$ needs to be chosen. A common choice is a Normal distribution centred at $\theta_i$ where the variance needs to be selected to have some level of optimality in the performance of the algorithm \citep{Roberts2001}. An automated tuning process for the variance of the proposal distribution $q(\theta_i,\theta_i')$ was introduced by Roberts and Rosenthal, 2009 \citep{Roberts2009}. This \emph{adaptive Metropolis-Hastings} algorithm is often used in combination with Gibbs sampling (\emph{adaptive Metropolis-within-Gibbs sampling}) to approximate the posterior distribution of model parameters for complex models \citep{Roberts2009}.\\

\textbf{\textit{Practical considerations}}

Thinning, Burn-in \cite{Greyer1992}

\subsection{Variational Bayes}

When datasets are large and models are complex, it is not always feasible to use the above described MCMC sampling methods to derive posterior distributions. Variational inference derives an approximate posterior distribution by optimization. The principle of variational inference is to select a member of a family of approximate densities $Q$ by minimizing the Kullback-Leibler divergence:

\begin{equation}
q^\ast(\mathbf{z})=\underset{q(\mathbf{z})\in{}Q}{\textnormal{argmin\,{}KL}}(q(\mathbf{z})||p(\mathbf{z}|\mathbf{x}))
\end{equation}

The posterior distribution is approximated with the optimized member of the family $q^\ast(\mathbf{z})$\citep{Blei2017}.\\
In general, variational inference tends to be faster than MCMC while MCMC allows producing exact samples from the target density \citep{Blei2017}. Therefore, variational inferences is preferred when datasets are large and exact samples are not needed.

\todo{Maximisation of the evidence lower bound}

\subsection{Bayesian decision theory}

\subsection{Modelling scRNA-Seq data}

As described above, expression counts in single-cell RNA-Seq data can be modelled as negative binomial distributed [ZINBABWE] while other approaches model these counts as log-normal distributed [BISCUIT, ZIFA]. This approach estimates cell and gene-specific parameters that can be used downstream for several tasks as normlization [Catas Nat Methods], clustering [ref], visualization [some latent space...] and imputation [MAGIC?], differential expression [e.g. MAST].  

\subsection{BASiCS: Bayesian Inference of Single-Cell Sequencing data} 

\subsection{Scalability of Bayesian inference}

With the development of dropblet based approaches [Klein, Macosko] and multiplexed sequencing [Seqwell], scalability is important.

Stochastic optimization as principle to scale models.

Single-cell Variational Inference (scVI) 

scVI: transcriptomes of each cell are encoded through a non-linear transformation into a low-dimensional latent vector of normal random variables. latent representation is non-linearly transformed to generate a posterior distribution of model parameters based on a zer0-inflated negative binomial model. 

Zero-inflated negative binomial [Love 2014, Grun 2014, ZinBAWave]

The transcript count $x_{n,g}$ of gene $g$ in cell $n$ is modelled as zero-inflated negative binomial distributed:

\begin{align*}
x_{n,g} & = 
 \left\lbrace
  \begin{aligned}
    & y_{n,g} && \textnormal{if} \; h_{n,g} = 0,  \\ 
    & 0 && \textnormal{otherwise}    	    
  \end{aligned}
\right.\\
h_{n,g} & \sim \textnormal{Bernoulli}(f_h^g(z_n,s_n))\\
y_{n,g} & \sim \textnormal{Poisson}(l_nw_{n.g})\\
w_{n,g} & \sim \textnormal{Gamma}(\rho^g_n, \theta)\\
\rho_n & = f_w(z_n,s_n)\\
l_n & \sim \textnormal{log-Normal}(l_{\mu},l^2_{\sigma})\\
z_n & \sim \textnormal{Normal}(0,I)
\end{align*}

\todo{add graphical model}

In this model, the negative binomial distribution is realized as a hierarchical formulation of $y_{n,g}$ being Poisson distributed around the latent random variable $l_n$ with an additional random effect $w_{n,g}$. Additionally, the zero-inflation of the model is controlled by the latent variable $h_{n,g}$. $l_n$ is a random variable that represents nuisance variation due to differences in capture efficiency and sequencing depth and which correlates with log-library size. $l_n$ is log-normal distributed parameterized by $l_\mu,l_\sigma\in\mathbb{R}^B_+$ which are empirical mean and variance estimates of the log-library size per batch in $B$ and which are therefore constants in the model \textbf{(Fig.~\ref{fig0:scVI}A)}.\\

$w_{n,g}$ is Gamma distributed with the shape parameter $\rho_n^g$ and the scale parameter $\theta$. $\rho_g$ represents an intermediate matrix that relates the observations $x_{n,g}$ to the latent variables $z_n$. It provides a batch-corrected, normalized estimate of the percentage of transcripts in each cell $n$ from each gene $g$. $\theta$ is a global inverse-dispersion variable shared across all genes and all cells. The latent variable $z_n$ captures a latent representation of the data reflecting biological variation between the cells. $f_w$ and $f_h$ are neural networks mapping the latent space and batch annotation back to the full dimension of all genes: $\mathbb{R}^d\times{}\left\lbrace0,1\right\rbrace^B\rightarrow\mathbb{R}^G$.\\

Fast inference of this model is implemented via stochastic optimization. First, the latent variables $w_{n,g}$, $h_{n,g}$ and $y_{n,g}$ are integrated out by controlling that $p(x_{n,g}|z_n,l_n,s_n)$ has a closed form density and is zero-inflated negative binomial (see Appendix A in \citep{Lopez2018}). In this formulation, the distribution of $x_{n,g}$ is only conditioned on the latent variables $z_n$ and $l_n$. The posterior distributions has therefore the following form: $p(z_n,l_n|x_{n,g},s_n)$. Mean-field variational inference is used to parameterized the posterior as:

\begin{equation}
p(z_n,l_n|x_{n,g},s_n)=p(z_n|x_{n,g},s_n)p(l_n|x_{n,g},s_n)
\end{equation} 






scRNA-Seq data is better fitted with a ZINB than log-Normal or zero-inflated log-Normal [Lopez2018]. 

scVI accounts for batch effects, normalizes data, provides low-dimensional representation, takes 5 hours for > 1 million cells and 750 genes and 10 hours for > 1 million cells and 10,000 genes.

Differential mean expression testing via Bayes factor:

\todo{Write model for differential testing}


Summary: Zero-inflation is not needed and zeros in dataset can be explained by NB distribution [Lopez2018]. And when number of cells is smaller than number of genes, model underfits. Strength: representation of data in latent space


\subsection{Neural networks for modelling scRNA-Seq data}

\subsection{Other applications for Bayesian model using scRNA-Seq data}
 

